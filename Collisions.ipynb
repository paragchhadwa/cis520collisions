{"cells":[{"cell_type":"code","source":["collision_data = sqlContext.read.format('com.databricks.spark.csv').options(header='true',inferSchema='true').load('/FileStore/tables/mue9q9ad1469238369776/Collisions_Data.xlsx')\n"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["%sql\nCREATE TABLE COLLISONS_L (\n    lat string,  \n  lon string,  \n  object_id int,  \n  case_id int,  \n  acc_year int,  \n  proc_data String,  \n  juris int,  \n  collision_data String,  \n  coll_time int,  \n  officer_id int,  \n  reporting_district int,  \n  day_of_week int,  \n  shift int,  \n  population int,  \n  cnty_city_loc int,  \n  datapoint float,  \n  special_cond int,  \n  beat_type int,  \n  chp_beat_type int,  \n  city_div string,  \n  chp_beat_class int,  \n  beat_numb string,  \n  primary_rd string,  \n  secondary_rd string,  \n  distance int,  \n  direction string,  \n  intersection string,  \n  weather_1 string,  \n  weather_2 string,  \n  state_hwy string,  \n  caltrans_county string,  \n  caltrans_dis string,  \n  state_route int,  \n  route_suffix string,  \n  postmile string,  \n  loc_type string,  \n  ramp_inter string,  \n  side_of_hwy string,  \n  tow_awy string,  \n  coll_sev int,  \n  num_killed int,  \n  num_inj int,  \n  party_count int,  \n  prim_coll_fac string,  \n  pcf_code_vil string,  \n  pcf_code_cat string,  \n  pcf_vil string,  \n  pcf_vil_sub string,  \n  hit_run string,  \n  type_of_coll string,  \n  mviw string,  \n  ped_action string,  \n  road_surf string,  \n  road_cond_1 string,  \n  road_cond_2 string,  \n  lighting string,  \n  control_device string,  \n  chp_row_type string,  \n  pedesterian string,  \n  bicycle string,  \n  motorcycle string,  \n  truck string,  \n  not_private_prop string,  \n  alchohol_ivolved string,  \n  stwd_vec_type string,  \n  chp_vec_type_fault string,  \n  sev_inj_count string,  \n  vis_inj_count string,  \n  complain_plan_count string,  \n  ped_killed_count string,  \n  ped_inj_count string,  \n  bicycle_killed_count string,  \n  bicycle_killed_inj string,  \n  motor_killed_count string,  \n  motor_inj_count string,  \n  primary_ramp string,  \n  sec_ramp string,  \n  latitude string,  \n  longitude string,  \n  time_cat int,  \n  month string,  \n  city string,  \n  country string,  \n  state string,  \n  point_x string,  \n  point_y string,  \n  match_address string,  \n  primary_yard string,  \n  secondary_yard string  \n )\nUSING com.databricks.spark.csv\nOPTIONS (path \"/FileStore/tables/8qifqlgk1469240528424/Collisions_20092013_SWITRS__1_-d74ea.csv\", header \"true\")\n\n"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["display(sqlContext.sql(\"SELECT LAT as long,LON as lat from COLLISONS_L\"))"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["display(sqlContext.sql(\"SELECT acc_year FROM COLLISONS_L\"))"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["number of collisions per year"],"metadata":{}},{"cell_type":"code","source":["display(sqlContext.sql(\"SELECT count(*),acc_year as year from COLLISONS_L group by acc_year\"))"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["season_data=sqlContext.sql(\"select case when month between 1 and 3 then 'Winter' when month between 3 and 6 then 'Spring' when month between 6 and 7 then 'Summer' when month between 7 and 12 then 'Fall' end as month from COLLISONS_L where month is not null\")"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["from pyspark.sql.functions import col\ndisplay(season_data.groupby('month').count().sort(col('month')))"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["coll during different times"],"metadata":{}},{"cell_type":"code","source":["time_data=sqlContext.sql(\"select case when coll_time between 0 and 200 then '00:00-2:00' when coll_time between 200 and 400 then '02:00-04:00' when coll_time between 400 and 600 then '04:00-06:00' when coll_time between 600 and 800 then '06:00-08:00' when coll_time between 800 and 1000 then '08:00-10:00' when coll_time between 1000 and 1200 then '10:00-12:00' when coll_time between 1200 and 1400 then '12:00-14:00' when coll_time between 1400 and 1600 then '14:00-16:00' when coll_time between 1600 and 1800 then '16:00-18:00' when coll_time between 1800 and 2000 then '18:00-20:00' when coll_time between 2000 and 2200 then '20:00-22:00' when coll_time between 2200 and 2400 then '22:00-00:00' end as coll_time from COLLISONS_L where coll_time is not null\")"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["from pyspark.sql.functions import col\ndisplay(time_data.groupby('coll_time').count().sort(col('coll_time')))"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["coll for different days of the week"],"metadata":{}},{"cell_type":"code","source":["\ndisplay(sqlContext.sql(\"SELECT count(*),day_of_week as year from COLLISONS_L group by day_of_week\"))\n"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["number of alchohol cases involved for year"],"metadata":{}},{"cell_type":"code","source":["display(sqlContext.sql(\"SELECT count(*),acc_year as year from COLLISONS_L where alchohol_ivolved='Y' group by acc_year\"))\n"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["no of coll for each day when alochol is involved"],"metadata":{}},{"cell_type":"code","source":["display(sqlContext.sql(\"SELECT count(*),day_of_week as day from COLLISONS_L where alchohol_ivolved='Y' group by day_of_week\"))\n"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["import math\n\ndef distance(lat1,lon1):\n   try:\n   \n    lat2 = 34.0654\n    lon2 = -118.1721\n    radius_in_miles = 3965\n\n    dlat = math.radians(lat2-lat1)\n    dlon = math.radians(lon2-lon1)\n    a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) \\\n        * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)\n    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n    d = radius_in_miles * c\n\n    return d\n   except:\n    return 0.0"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["number of accidents near CSU LA"],"metadata":{}},{"cell_type":"code","source":["lat_lon = sqlContext.sql(\"SELECT case_id,CAST(LON as float),CAST(LAT as float) FROM COLLISONS_L\");"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["distance_data=lat_lon.map(lambda (x,y,z):(x,distance(y,z)))"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["distance_df=distance_data.toDF(['id','distance'])"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["distance_df.registerTempTable(\"distance_table\")"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["distance_data=sqlContext.sql(\"select case when distance between 0 and 5 then '0-5' when distance between 5 and 10 then '5-10' when distance between 10 and 15 then '10-15' when distance between 15 and 20 then '15-20' when distance between 20 and 25 then '20-25' when distance between 25 and 30 then '25-30' else '>30' end as distance from distance_table where distance is not null\")"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["from pyspark.sql.functions import col\ndisplay(distance_data.groupby('distance').count().sort(col('distance')))"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["map data under 5 miles from CSULA"],"metadata":{}},{"cell_type":"code","source":["distance_data_map=lat_lon.map(lambda (x,y,z):(x,distance(y,z),y,z))"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["distance_data_map_csula=distance_data_map.toDF(['id','distance','lon','lat'])"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["distance_data_map_csula.registerTempTable(\"distance_table_map_csula\")"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["display(sqlContext.sql(\"SELECT * FROM distance_table_map_csula where distance < 5\"))"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["/FileStore/tables/sip0g0jm1469246874616/Victim_Tables__Collisions_20092013_SWITRS.csv\n"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["%sql\nCREATE TABLE COLLISONS_VICTIM(\n    object_id int,  \n  case_id int,  \n  party_numb int,  \n  victim_role string,  \n  victim_sex string,  \n  victim_age int,  \n  victim_deg_inj int,  \n  victim_seating_pos String,  \n  victim_safety_equip1 String,  \n  victim_safety_equip2 String, \n victim_ejected string, \n  accident_year string\n )\nUSING com.databricks.spark.csv\nOPTIONS (path \"/FileStore/tables/sip0g0jm1469246874616/Victim_Tables__Collisions_20092013_SWITRS.csv\", header \"true\")"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":["Victim Sex"],"metadata":{}},{"cell_type":"code","source":["display(sqlContext.sql(\"SELECT count(*) as total,victim_sex from COLLISONS_VICTIM group by victim_sex\"))"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":["Victim Severity"],"metadata":{}},{"cell_type":"code","source":["display(sqlContext.sql(\"SELECT count(*) as total,victim_deg_inj from COLLISONS_VICTIM group by victim_deg_inj\"))"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["victim_data=sqlContext.sql(\"select case when victim_age between 0 and 10 then '0-10' when victim_age between 10 and 20 then '10-20' when victim_age between 20 and 30 then '20-30' when victim_age between 30 and 40 then '30-40' when victim_age between 40 and 50 then '40-50' when victim_age between 50 and 60 then '50-60' when victim_age between 60 and 70 then '60-70' else '>70' end as victim_age from COLLISONS_VICTIM where victim_age is not null\")"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["from pyspark.sql.functions import col\ndisplay(victim_data.groupby('victim_age').count().sort(col('victim_age')))"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["/FileStore/tables/8tgkixcf1469248660605/Party_Tables__Collisions_20092013_SWITRS.csv\n"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":["Party Table"],"metadata":{}},{"cell_type":"code","source":["%sql\nDROP TABLE IF EXISTS COLLISONS_PARTY;"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["%sql\nDROP TABLE IF EXISTS COLLISONS_PARTY;\nCREATE TABLE COLLISONS_PARTY(\n  object_id int,  \n  case_id int,  \n  party_numb int,  \n  party_type string,  \n  at_fault string,  \n  party_sex string,  \n  party_age int,  \n  party_sobrity String,  \n  party_drug_physical String,  \n  direction_of_travel String, \n party_safety_equip1 string, \n  party_safety_equip2 string,\n  finance_response string,\n  sp_info1 string,\n  sp_info2 string,\n  sp_info3 string,\n  qaf_violation_code string,\n  qaf_violation_cat string,\n    qaf_violation_section string,\n  qaf_violation_suffix string,\n  qaf12 string,\nparty_numb_killed string,\n  party_numb_injured string,\nmove_per_acc string,\n  vech_year string,\n  vech_make string,\n  sdwd_vech_type string,\n  chp_vech_type_towing string,\n    chp_vech_type_towed string,\nrace string,\n  in_attention string,\n  special_info_f string,\n    special_info_g string,\nacc_year string\n )\nUSING com.databricks.spark.csv\nOPTIONS (path \"/FileStore/tables/8tgkixcf1469248660605/Party_Tables__Collisions_20092013_SWITRS.csv\", header \"true\")"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":["Party Sex"],"metadata":{}},{"cell_type":"code","source":["display(sqlContext.sql(\"SELECT count(*) as total,party_sex from COLLISONS_PARTY group by party_sex\"))"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":["Party age"],"metadata":{}},{"cell_type":"code","source":["party_data=sqlContext.sql(\"select case when party_age between 0 and 10 then '0-10' when party_age between 10 and 20 then '10-20' when party_age between 20 and 30 then '20-30' when party_age between 30 and 40 then '30-40' when party_age between 40 and 50 then '40-50' when party_age between 50 and 60 then '50-60' when party_age between 60 and 70 then '60-70' else '>70' end as party_age from COLLISONS_PARTY where party_age is not null\")"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["from pyspark.sql.functions import col\ndisplay(party_data.groupby('party_age').count().sort(col('party_age')))"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["display(sqlContext.sql(\"SELECT count(*) as total,sdwd_vech_type from COLLISONS_PARTY group by sdwd_vech_type\"))"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["display(sqlContext.sql(\"SELECT count(*) as total,vech_make from COLLISONS_PARTY group by vech_make\"))"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":50}],"metadata":{"name":"Collisions","notebookId":342097616782562},"nbformat":4,"nbformat_minor":0}
